{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36ecd96",
   "metadata": {},
   "source": [
    "# 金融异常检测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3e862",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.26.4  \n",
    "- pytorch = 2.3.1  \n",
    "- torch_geometric = 2.5.3  \n",
    "- torch_scatter = 2.1.2  \n",
    "- torch_sparse = 0.6.18  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be457559",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e6d3b",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b56c4d",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2dbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "#设置gpu设备\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0cfeb",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4397e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_index=[2, 4300999], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "20\n",
      "torch.Size([3700550])\n",
      "torch.Size([2, 4300999])\n"
     ]
    }
   ],
   "source": [
    "path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n",
    "save_dir='./results/' #模型保存路径\n",
    "dataset_name='DGraph'\n",
    "# dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor(remove_edge_index=False))\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2    #本实验中仅需预测类0和类1\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n",
    "\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "result_dir = prepare_folder(dataset_name,'mlp')\n",
    "\n",
    "# 输出\n",
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.x.size(-1))  #20\n",
    "print(data.y.shape)  #label\n",
    "print(data.edge_index.shape)  # 应该是 [2, num_edges]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d5e31",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e9bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_index=[2, 4300999], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "20\n",
      "torch.Size([3700550])\n",
      "torch.Size([2, 4300999])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.x.size(-1))  #20\n",
    "print(data.y.shape)  #label\n",
    "print(data.edge_index.shape)  # 应该是 [2, num_edges]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e4cc9",
   "metadata": {},
   "source": [
    "### 2.4 定义模型\n",
    "这里我们使用简单的多层感知机作为例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7b6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dcae0d",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr`：学习率；\n",
    "- `num_layers`：网络的层数；\n",
    "- `hidden_channels`：隐藏层维数；\n",
    "- `dropout`：dropout比例；\n",
    "- `weight_decay`：正则化项的系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecae885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_parameters = {\n",
    "#     'lr': 0.01\n",
    "#     , 'num_layers': 2\n",
    "#     , 'hidden_channels': 128\n",
    "#     , 'dropout': 0.0\n",
    "#     , 'batchnorm': False\n",
    "#     , 'weight_decay': 5e-7\n",
    "#                   }\n",
    "# epochs = 200\n",
    "# log_steps =10 # log记录周期\n",
    "\n",
    "\n",
    "mlp_parameters = {\n",
    "    'lr': 0.01,\n",
    "    'num_layers': 3,\n",
    "    'hidden_channels': 128,\n",
    "    'dropout': 0.0,\n",
    "    'batchnorm': False,\n",
    "    'weight_decay': 5e-7\n",
    "}\n",
    "\n",
    "epochs = 600\n",
    "final_lr = 0.001\n",
    "log_steps = 10  # log记录周期\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658acde",
   "metadata": {},
   "source": [
    "初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n",
    "\n",
    "具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af8c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP initialized\n"
     ]
    }
   ],
   "source": [
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "\n",
    "eval_metric = 'auc'  #使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa089391",
   "metadata": {},
   "source": [
    "**下面是修改以使用其他图神经网络替代MLP（GAT或者GraphSAGE）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da16655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 GraphSAGE 替换 MLP\n",
    "from typing import Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x.log_softmax(dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3920a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样可以配置后续训练、验证、推理用到的参数。超参设置如下：\n",
    "\n",
    "# epochs: 在训练集上训练的代数；\n",
    "# lr: 学习率；\n",
    "# num_layers: 网络的层数；\n",
    "# hidden_channels: 隐藏层维数；\n",
    "# dropout: dropout比例；\n",
    "# weight_decay: 正则化项的系数。\n",
    "sage_parameters = {\n",
    "    'lr':0.01\n",
    "    , 'num_layers':2\n",
    "    , 'hidden_channels':128\n",
    "    , 'dropout':0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay':5e-7\n",
    "}\n",
    "epochs = 200\n",
    "log_steps = 10  # log记录周期\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23830249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GraphSAGE initialized\n"
     ]
    }
   ],
   "source": [
    "# 初始化 GraphSAGE 模型，并使用 AUC 作为评价指标：\n",
    "para_dict = sage_parameters\n",
    "model_para = sage_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = GraphSAGE(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n",
    "print(f'Model GraphSAGE initialized')\n",
    "\n",
    "eval_metric = 'auc'  # 使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b9f59",
   "metadata": {},
   "source": [
    "### 2.5 训练\n",
    "\n",
    "使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a70625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "     # data.y is labels of shape (N, )\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x[train_idx])\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcfea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, split_idx, evaluator):\n",
    "    # data.y is labels of shape (N, )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        losses, eval_results = dict(), dict()\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "\n",
    "            out = model(data.x[node_id])\n",
    "            y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "            losses[key] = F.nll_loss(out, data.y[node_id]).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred)[eval_metric]\n",
    "\n",
    "    return eval_results, losses, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "464f25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19458\n",
      "Epoch: 10, Loss: 0.1239, Train: 68.858, Valid: 68.223 \n",
      "Epoch: 20, Loss: 0.0669, Train: 55.576, Valid: 55.797 \n",
      "Epoch: 30, Loss: 0.0658, Train: 70.529, Valid: 69.833 \n",
      "Epoch: 40, Loss: 0.0646, Train: 70.346, Valid: 69.910 \n",
      "Epoch: 50, Loss: 0.0644, Train: 70.910, Valid: 70.337 \n",
      "Epoch: 60, Loss: 0.0642, Train: 71.209, Valid: 70.559 \n",
      "Epoch: 70, Loss: 0.0640, Train: 71.453, Valid: 70.747 \n",
      "Epoch: 80, Loss: 0.0639, Train: 71.597, Valid: 70.858 \n",
      "Epoch: 90, Loss: 0.0639, Train: 71.714, Valid: 70.920 \n",
      "Epoch: 100, Loss: 0.0639, Train: 71.804, Valid: 70.975 \n",
      "Epoch: 110, Loss: 0.0638, Train: 71.895, Valid: 71.037 \n",
      "Epoch: 120, Loss: 0.0638, Train: 71.971, Valid: 71.103 \n",
      "Epoch: 130, Loss: 0.0638, Train: 72.043, Valid: 71.157 \n",
      "Epoch: 140, Loss: 0.0638, Train: 72.107, Valid: 71.211 \n",
      "Epoch: 150, Loss: 0.0637, Train: 72.170, Valid: 71.264 \n",
      "Epoch: 160, Loss: 0.0637, Train: 72.233, Valid: 71.319 \n",
      "Epoch: 170, Loss: 0.0637, Train: 72.299, Valid: 71.378 \n",
      "Epoch: 180, Loss: 0.0637, Train: 72.364, Valid: 71.433 \n",
      "Epoch: 190, Loss: 0.0636, Train: 72.428, Valid: 71.495 \n",
      "Epoch: 200, Loss: 0.0636, Train: 72.495, Valid: 71.563 \n",
      "Epoch: 210, Loss: 0.0636, Train: 72.574, Valid: 71.641 \n",
      "Epoch: 220, Loss: 0.0635, Train: 72.648, Valid: 71.704 \n",
      "Epoch: 230, Loss: 0.0635, Train: 72.704, Valid: 71.729 \n",
      "Epoch: 240, Loss: 0.0635, Train: 72.745, Valid: 71.745 \n",
      "Epoch: 250, Loss: 0.0635, Train: 72.773, Valid: 71.754 \n",
      "Epoch: 260, Loss: 0.0635, Train: 72.796, Valid: 71.759 \n",
      "Epoch: 270, Loss: 0.0635, Train: 72.818, Valid: 71.763 \n",
      "Epoch: 280, Loss: 0.0634, Train: 72.839, Valid: 71.768 \n",
      "Epoch: 290, Loss: 0.0634, Train: 72.859, Valid: 71.775 \n",
      "Epoch: 300, Loss: 0.0634, Train: 72.877, Valid: 71.780 \n",
      "Epoch: 310, Loss: 0.0634, Train: 72.894, Valid: 71.782 \n",
      "Epoch: 320, Loss: 0.0634, Train: 72.910, Valid: 71.786 \n",
      "Epoch: 330, Loss: 0.0634, Train: 72.926, Valid: 71.789 \n",
      "Epoch: 340, Loss: 0.0634, Train: 72.942, Valid: 71.789 \n",
      "Epoch: 350, Loss: 0.0634, Train: 72.957, Valid: 71.791 \n",
      "Epoch: 360, Loss: 0.0634, Train: 72.972, Valid: 71.792 \n",
      "Epoch: 370, Loss: 0.0634, Train: 72.989, Valid: 71.788 \n",
      "Epoch: 380, Loss: 0.0634, Train: 73.004, Valid: 71.792 \n",
      "Epoch: 390, Loss: 0.0633, Train: 73.020, Valid: 71.793 \n",
      "Epoch: 400, Loss: 0.0633, Train: 73.037, Valid: 71.788 \n",
      "Epoch: 410, Loss: 0.0633, Train: 73.050, Valid: 71.783 \n",
      "Epoch: 420, Loss: 0.0633, Train: 73.061, Valid: 71.781 \n",
      "Epoch: 430, Loss: 0.0633, Train: 73.073, Valid: 71.778 \n",
      "Epoch: 440, Loss: 0.0633, Train: 73.086, Valid: 71.778 \n",
      "Epoch: 450, Loss: 0.0633, Train: 73.099, Valid: 71.777 \n",
      "Epoch: 460, Loss: 0.0633, Train: 73.100, Valid: 71.777 \n",
      "Epoch: 470, Loss: 0.0633, Train: 73.102, Valid: 71.776 \n",
      "Epoch: 480, Loss: 0.0633, Train: 73.103, Valid: 71.776 \n",
      "Epoch: 490, Loss: 0.0633, Train: 73.104, Valid: 71.776 \n",
      "Epoch: 500, Loss: 0.0633, Train: 73.105, Valid: 71.776 \n",
      "Epoch: 510, Loss: 0.0633, Train: 73.107, Valid: 71.775 \n",
      "Epoch: 520, Loss: 0.0633, Train: 73.108, Valid: 71.775 \n",
      "Epoch: 530, Loss: 0.0633, Train: 73.109, Valid: 71.774 \n",
      "Epoch: 540, Loss: 0.0633, Train: 73.111, Valid: 71.774 \n",
      "Epoch: 550, Loss: 0.0633, Train: 73.112, Valid: 71.774 \n",
      "Epoch: 560, Loss: 0.0633, Train: 73.113, Valid: 71.774 \n",
      "Epoch: 570, Loss: 0.0633, Train: 73.114, Valid: 71.774 \n",
      "Epoch: 580, Loss: 0.0633, Train: 73.116, Valid: 71.774 \n",
      "Epoch: 590, Loss: 0.0633, Train: 73.117, Valid: 71.774 \n",
      "Epoch: 600, Loss: 0.0633, Train: 73.119, Valid: 71.774 \n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    # 在前400个epoch中，学习率保持为0.01\n",
    "    if epoch <= 450:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.01\n",
    "    # 在后100个epoch中，学习率调整为0.001\n",
    "    else:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = final_lr\n",
    "    \n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n",
    "              f'Valid: {100 * valid_eval:.3f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd0a72",
   "metadata": {},
   "source": [
    "**修改后的训练如下（SAGE）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd560ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_para = {\n",
    "    'epoch':500\n",
    "    , 'runs':10\n",
    "    , 'log_steps':10\n",
    "}\n",
    "para_dict.update(addition_para)\n",
    "\n",
    "# 定义输出类\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 2\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                best_results.append((train1, valid, train2))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            highest_train, highest_train_std = r.mean().item(), r.std().item()\n",
    "            print(f'Highest Train: {r.mean():.4f} ± {r.std():.4f}')\n",
    "            r = best_result[:, 1]\n",
    "            highest_valid, highest_valid_std = r.mean().item(), r.std().item()\n",
    "            print(f'Highest Valid: {r.mean():.4f} ± {r.std():.4f}')\n",
    "            r = best_result[:, 2]\n",
    "            final_train, final_train_std = r.mean().item(), r.std().item()\n",
    "            print(f'  Final Train: {r.mean():.4f} ± {r.std():.4f}')\n",
    "            \n",
    "            return {'train': round(final_train, 4)\n",
    "                    , 'train_std': round(final_train_std, 4)\n",
    "                    , 'valid': round(highest_valid, 4)\n",
    "                    , 'valid_std': round(highest_valid_std, 4)\n",
    "                   }\n",
    "        \n",
    "logger = Logger(runs= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b027fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, no_conv=False):\n",
    "    # data.y is labels of shape (N, ) \n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    if no_conv:\n",
    "        out = model(data.x[train_idx])\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)[train_idx]\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, no_conv=False):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    if no_conv:\n",
    "        out = model(data.x)\n",
    "    else:\n",
    "        out = model(data.x, data.adj_t)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "    \n",
    "    losses, eval_results = dict(), dict()\n",
    "    for key in ['train', 'valid']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "        eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "            \n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.virtualenvs/basenv/lib/python3.9/site-packages/torch_sparse/tensor.py:574: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n"
     ]
    }
   ],
   "source": [
    "best_model_dict = None\n",
    "for run in range(para_dict['runs']):\n",
    "\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    model.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "    best_valid = 0\n",
    "    min_valid_loss = 1e8\n",
    "    best_out = None\n",
    "\n",
    "    for epoch in range(1, para_dict['epoch']+1):\n",
    "        loss = train(model, data, train_idx, optimizer)\n",
    "        eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "        train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "        train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "#                 if valid_eval > best_valid:\n",
    "#                     best_valid = valid_result\n",
    "#                     best_out = out.cpu().exp()\n",
    "        if valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            best_out = out.cpu()\n",
    "            best_model_dict =  model.state_dict()\n",
    "        if epoch % para_dict['log_steps'] == 0:\n",
    "            print(f'Run: {run + 1:02d}, '\n",
    "                        f'Epoch: {epoch:02d}, '\n",
    "                        f'Loss: {loss:.4f}, '\n",
    "                        f'Train: {100 * train_eval:.3f}%, '\n",
    "                        f'Valid: {100 * valid_eval:.3f}% ')\n",
    "        logger.add_result(run, [train_eval, valid_eval])\n",
    "    \n",
    "    logger.print_statistics(run)\n",
    "    torch.save(best_model_dict,save_dir+f'epoch500-SAGE{run}-{100 * valid_eval:.3f}.pt',_use_new_zipfile_serialization=False)\n",
    "    \n",
    "final_results = logger.print_statistics()\n",
    "print('final_results:', final_results)\n",
    "para_dict.update(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2fd9d",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a8647f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af6b6614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9962, 0.0038])\n",
      "节点 0 预测对应的标签为:0, 为正常用户。\n",
      "tensor([0.9764, 0.0236])\n",
      "节点 1 预测对应的标签为:0, 为正常用户。\n"
     ]
    }
   ],
   "source": [
    "dic={0:\"正常用户\",1:\"欺诈用户\"}\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "node_idx = 1\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c2157",
   "metadata": {},
   "source": [
    "**修改后的模型预测如下**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32dbba7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 加载验证集上表现最好的模型\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m(torch\u001b[38;5;241m.\u001b[39mload(save_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(data, node_id):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    加载模型并进行预测\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    :param node_id: int, 需要进行预测的节点的下标\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    :return: tensor, 类0以及类1的概率, torch.size[1,2]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "# 加载验证集上表现最好的模型\n",
    "model.load_state_dict(torch.load(save_dir+'/model_sage.pt'))\n",
    "\n",
    "def predict(data, node_id):\n",
    "    \"\"\"\n",
    "    加载模型并进行预测\n",
    "    :param node_id: int, 需要进行预测的节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # 切换模型到评估模式\n",
    "        out = model(data.x[node_id], data.edge_index)  # 使用 GraphSAGE 模型进行预测\n",
    "        y_pred = out.exp()  # (N, num_classes) 计算概率\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# 使用预训练的模型对指定节点进行预测，并输出结果：\n",
    "# 标签字典\n",
    "dic = {0: \"正常用户\", 1: \"欺诈用户\"}\n",
    "\n",
    "# 对节点 0 进行预测\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为: {torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "# 对节点 1 进行预测\n",
    "node_idx = 1\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为: {torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7190811c",
   "metadata": {},
   "source": [
    "**下面是一些存档的历史代码与中间过程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 暂时的结果：\n",
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 定义 GraphSAGE 模型\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# 初始化模型\n",
    "model = GraphSAGE(in_channels=20, \n",
    "                  hidden_channels=128, \n",
    "                  out_channels=2,  # 假设是二分类\n",
    "                  num_layers=2, \n",
    "                  dropout=0.5)\n",
    "\n",
    "\n",
    "# 这里可以加载你的模型\n",
    "model = model.load_state_dict(torch.load('./results/model_sage.pt'))\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "#         out = model(data.x[node_id])\n",
    "#         y_pred = out.exp()  # (N,num_classes)\n",
    "        # 使用 GraphSAGE 模型进行预测时，需要传入 edge_index\n",
    "        out = model(data.x, data.edge_index)  # 全图推理\n",
    "        y_pred = out[node_id].exp()  # 取出指定节点的预测概率 (N, num_classes)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651221b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保持原有MLP，稍作修改的结果：AUC：0.722\n",
    "# 模型预测部分如下\n",
    "\n",
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# 初始化模型\n",
    "mlp_parameters = {\n",
    "    'lr': 0.01\n",
    "    , 'num_layers': 2\n",
    "    , 'hidden_channels': 128\n",
    "    , 'dropout': 0.0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay': 5e-7\n",
    "                  }\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期\n",
    "\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=20, out_channels=2, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "# 加载保存的模型参数\n",
    "model.load_state_dict(torch.load('./results/model.pt'), strict=False)\n",
    "\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2d23b",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5018b",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a17742f",
   "metadata": {
    "select": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP initialized\n"
     ]
    }
   ],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# 初始化模型\n",
    "mlp_parameters = {\n",
    "    'lr': 0.01,\n",
    "    'num_layers': 3,\n",
    "    'hidden_channels': 128,\n",
    "    'dropout': 0.0,\n",
    "    'batchnorm': False,\n",
    "    'weight_decay': 5e-7\n",
    "}\n",
    "\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期\n",
    "\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=20, out_channels=2, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "# 加载保存的模型参数\n",
    "model.load_state_dict(torch.load('./results/model.pt'), strict=False)\n",
    "\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fb23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
